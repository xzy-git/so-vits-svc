{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrsHTUilDoxQ"
      },
      "source": [
        "# 推理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gQcIZ8RsOkn",
        "outputId": "a45a2e08-203c-432d-a401-48a9699686c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 25 10:23:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    29W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# 查看显卡\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS6YNc7JqCw1",
        "outputId": "c80151bb-6a27-40cd-ed8c-dda14b1a3506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'so-vits-svc'...\n",
            "remote: Enumerating objects: 394, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 394 (delta 38), reused 33 (delta 33), pack-reused 342\u001b[K\n",
            "Receiving objects: 100% (394/394), 28.09 MiB | 15.82 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n"
          ]
        }
      ],
      "source": [
        "#@title 克隆的github仓库\n",
        "#@markdown ##选择要克隆的github仓库分支\n",
        "Clone = \"48k\" #@param [\"32k\",\"48k\"]\n",
        "if Clone == \"32k\":\n",
        "  !git clone https://github.com/xzy-git/so-vits-svc -b 3.032k\n",
        "elif Clone == \"48k\":\n",
        "  !git clone https://github.com/xzy-git/so-vits-svc -b 3.048k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXBLkXxL4T1O",
        "outputId": "7519511c-425f-46ee-e6f8-cb9ad5199ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/so-vits-svc\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyworld\n",
            "  Downloading pyworld-0.3.2.tar.gz (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyworld) (1.22.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from pyworld) (0.29.33)\n",
            "Building wheels for collected packages: pyworld\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.2-cp38-cp38-linux_x86_64.whl size=919626 sha256=9a1671ec1d3794543ccf41f6f0992cc1d0ff79ad1737922568cd6df7a8a12362\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/b1/d2/8c78d691f7d5b0bb4ba9993926db209429c92686476837627f\n",
            "Successfully built pyworld\n",
            "Installing collected packages: pyworld, praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.3 pyworld-0.3.2\n"
          ]
        }
      ],
      "source": [
        "#@title 安装依赖\n",
        "%cd /content/so-vits-svc\n",
        "!pip install pyworld praat-parselmouth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqf3W0d6ify",
        "outputId": "d83ac1d6-93c1-4b04-a0f8-7a1e8964a95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-25 10:24:12--  https://github.com/bshall/hubert/releases/download/v0.1/hubert-soft-0d54a1f4.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/417578841/6eaffd96-4bcb-4978-ac67-80857af26838?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230225%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230225T102413Z&X-Amz-Expires=300&X-Amz-Signature=71faa34a6ce0d7a0dbd992ec145516741722722709debf9be572deb0c1346d20&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=417578841&response-content-disposition=attachment%3B%20filename%3Dhubert-soft-0d54a1f4.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-02-25 10:24:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/417578841/6eaffd96-4bcb-4978-ac67-80857af26838?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230225%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230225T102413Z&X-Amz-Expires=300&X-Amz-Signature=71faa34a6ce0d7a0dbd992ec145516741722722709debf9be572deb0c1346d20&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=417578841&response-content-disposition=attachment%3B%20filename%3Dhubert-soft-0d54a1f4.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 378435957 (361M) [application/octet-stream]\n",
            "Saving to: ‘hubert/hubert-soft-0d54a1f4.pt’\n",
            "\n",
            "hubert-soft-0d54a1f 100%[===================>] 360.90M   225MB/s    in 1.6s    \n",
            "\n",
            "2023-02-25 10:24:14 (225 MB/s) - ‘hubert/hubert-soft-0d54a1f4.pt’ saved [378435957/378435957]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title 下载必要模型文件\n",
        "!wget -P hubert/ https://github.com/bshall/hubert/releases/download/v0.1/hubert-soft-0d54a1f4.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmUkpUmfn_Hs",
        "outputId": "8c52a703-2e68-47ff-9a4c-7b795b33d21d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title 加载Google云端硬盘\n",
        "#@markdown 加载Google云端硬盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiNCWprSPlKH",
        "outputId": "4ceb35d5-4f0f-4217-f657-c8f9e4e85c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.22.4)\n",
            "Installing collected packages: protobuf, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.1 protobuf-3.20.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (from onnxsim) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxsim) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxsim) (4.5.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxsim) (3.20.3)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pygments, mdurl, markdown-it-py, rich, onnxsim\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed markdown-it-py-2.2.0 mdurl-0.1.2 onnxsim-0.4.17 pygments-2.14.0 rich-13.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.0-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (23.1.21)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.22.4)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxoptimizer\n",
            "  Downloading onnxoptimizer-0.3.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (from onnxoptimizer) (1.13.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxoptimizer) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxoptimizer) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxoptimizer) (4.5.0)\n",
            "Installing collected packages: onnxoptimizer\n",
            "Successfully installed onnxoptimizer-0.3.8\n",
            "False\n",
            "True\n",
            "/content/drive/MyDrive/48k\n",
            "G_33000\n",
            "INFO:root:Loaded checkpoint '/content/drive/MyDrive/48k/G_33000.pth' (iteration 83)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input hidden_unit\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input pitch\n",
            "  warnings.warn(\n",
            "/content/so-vits-svc/onnx_export/utils.py:38: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert f0_coarse.max() <= 255 and f0_coarse.min() >= 1, (f0_coarse.max(), f0_coarse.min())\n",
            "/content/so-vits-svc/onnx_export/attentions.py:157: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert t_s == t_t, \"Relative attention is only available for self-attention.\"\n",
            "/content/so-vits-svc/onnx_export/attentions.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  pad_length = max(length - (self.window_size + 1), 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:203: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  slice_start_position = max((self.window_size + 1) - length, 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:205: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if pad_length > 0:\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "False\n",
            "True\n",
            "/content/drive/MyDrive/48k\n",
            "G_34000\n",
            "INFO:root:Loaded checkpoint '/content/drive/MyDrive/48k/G_34000.pth' (iteration 85)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input hidden_unit\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input pitch\n",
            "  warnings.warn(\n",
            "/content/so-vits-svc/onnx_export/utils.py:38: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert f0_coarse.max() <= 255 and f0_coarse.min() >= 1, (f0_coarse.max(), f0_coarse.min())\n",
            "/content/so-vits-svc/onnx_export/attentions.py:157: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert t_s == t_t, \"Relative attention is only available for self-attention.\"\n",
            "/content/so-vits-svc/onnx_export/attentions.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  pad_length = max(length - (self.window_size + 1), 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:203: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  slice_start_position = max((self.window_size + 1) - length, 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:205: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if pad_length > 0:\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "False\n",
            "True\n",
            "/content/drive/MyDrive/48k\n",
            "G_35000\n",
            "INFO:root:Loaded checkpoint '/content/drive/MyDrive/48k/G_35000.pth' (iteration 88)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input hidden_unit\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input pitch\n",
            "  warnings.warn(\n",
            "/content/so-vits-svc/onnx_export/utils.py:38: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert f0_coarse.max() <= 255 and f0_coarse.min() >= 1, (f0_coarse.max(), f0_coarse.min())\n",
            "/content/so-vits-svc/onnx_export/attentions.py:157: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert t_s == t_t, \"Relative attention is only available for self-attention.\"\n",
            "/content/so-vits-svc/onnx_export/attentions.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  pad_length = max(length - (self.window_size + 1), 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:203: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  slice_start_position = max((self.window_size + 1) - length, 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:205: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if pad_length > 0:\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "False\n",
            "True\n",
            "/content/drive/MyDrive/48k\n",
            "G_36000\n",
            "INFO:root:Loaded checkpoint '/content/drive/MyDrive/48k/G_36000.pth' (iteration 90)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input hidden_unit\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input pitch\n",
            "  warnings.warn(\n",
            "/content/so-vits-svc/onnx_export/utils.py:38: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert f0_coarse.max() <= 255 and f0_coarse.min() >= 1, (f0_coarse.max(), f0_coarse.min())\n",
            "/content/so-vits-svc/onnx_export/attentions.py:157: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert t_s == t_t, \"Relative attention is only available for self-attention.\"\n",
            "/content/so-vits-svc/onnx_export/attentions.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  pad_length = max(length - (self.window_size + 1), 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:203: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  slice_start_position = max((self.window_size + 1) - length, 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:205: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if pad_length > 0:\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "False\n",
            "True\n",
            "/content/drive/MyDrive/48k\n",
            "G_37000\n",
            "INFO:root:Loaded checkpoint '/content/drive/MyDrive/48k/G_37000.pth' (iteration 93)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input hidden_unit\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2040: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input pitch\n",
            "  warnings.warn(\n",
            "/content/so-vits-svc/onnx_export/utils.py:38: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert f0_coarse.max() <= 255 and f0_coarse.min() >= 1, (f0_coarse.max(), f0_coarse.min())\n",
            "/content/so-vits-svc/onnx_export/attentions.py:157: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert t_s == t_t, \"Relative attention is only available for self-attention.\"\n",
            "/content/so-vits-svc/onnx_export/attentions.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  pad_length = max(length - (self.window_size + 1), 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:203: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  slice_start_position = max((self.window_size + 1) - length, 0)\n",
            "/content/so-vits-svc/onnx_export/attentions.py:205: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if pad_length > 0:\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
            "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
          ]
        }
      ],
      "source": [
        "#@title 将模型导出为onnx供本地推理用\n",
        "!pip install onnx\n",
        "!pip install onnxsim\n",
        "!pip install onnxruntime\n",
        "!pip install onnxoptimizer\n",
        "\n",
        "#@markdown **是否导出onnx格式的hubert**\n",
        "export_hubert = False #@param {type:\"boolean\"}\n",
        "#@markdown **是否导出onnx格式的模型**\n",
        "export_model = True #@param {type:\"boolean\"}\n",
        "#@markdown **模型路径**\n",
        "model_path = \"/content/drive/MyDrive/48k\" #@param {type:\"string\"}\n",
        "#@markdown **pth模型文件名，如有多个，文件名以逗号分隔**\n",
        "model_files_input = \"G_33000,G_34000,G_35000,G_36000,G_37000\" #@param {type:\"string\"}\n",
        "model_files = model_files_input.split(',') \n",
        "\n",
        "for i in range(len(model_files)):\n",
        "  !python onnx_export/onnx_export.py --export_hubert \"{export_hubert}\" --export_model \"{export_model}\" --model_path \"{model_path}\" --model_file \"{model_files[i]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUlw6PA_xiG8",
        "outputId": "45b22c0d-cebf-406c-8711-3edf61f24a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-maad\n",
            "  Downloading scikit_maad-1.3.12-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.4/142.4 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from scikit-maad) (1.7.3)\n",
            "Requirement already satisfied: scikit-image>=0.17 in /usr/local/lib/python3.8/dist-packages (from scikit-maad) (0.18.3)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-maad) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from scikit-maad) (1.21.6)\n",
            "Requirement already satisfied: resampy>=0.2 in /usr/local/lib/python3.8/dist-packages (from scikit-maad) (0.4.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1->scikit-maad) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1->scikit-maad) (2.8.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.8/dist-packages (from resampy>=0.2->scikit-maad) (0.56.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.17->scikit-maad) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.17->scikit-maad) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.17->scikit-maad) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.17->scikit-maad) (3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.17->scikit-maad) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.17->scikit-maad) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17->scikit-maad) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17->scikit-maad) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17->scikit-maad) (1.4.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->resampy>=0.2->scikit-maad) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->resampy>=0.2->scikit-maad) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->resampy>=0.2->scikit-maad) (57.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1->scikit-maad) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.53->resampy>=0.2->scikit-maad) (3.11.0)\n",
            "Installing collected packages: scikit-maad\n",
            "Successfully installed scikit-maad-1.3.12\n"
          ]
        }
      ],
      "source": [
        "#@title 如需在线推理，则加载模型\n",
        "\n",
        "!pip install scikit-maad\n",
        "\n",
        "import io\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile\n",
        "import IPython.display as ipd\n",
        "from inference import infer_tool\n",
        "from inference import slicer\n",
        "from inference.infer_tool import Svc\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "chunks_dict = infer_tool.read_temp(\"inference/chunks_temp.json\")\n",
        "\n",
        "#@markdown 模型文件夹位置\n",
        "cloud_model_folder = \"/content/drive/MyDrive/48k\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 模型文件名\n",
        "cloud_model_name = \"G_5000.pth\" #@param {type:\"string\"}\n",
        "\n",
        "cloud_model_path = cloud_model_folder + \"/\" + cloud_model_name\n",
        "\n",
        "#@markdown 配置文件位置\n",
        "cloud_config_path = \"/content/drive/MyDrive/48k/config.json\" #@param {type:\"string\"}\n",
        "\n",
        "!cp -f {cloud_config_path} /content/so-vits-svc/configs\n",
        "!cp {cloud_model_path} /content/so-vits-svc/logs/48k\n",
        "\n",
        "model_path = \"/content/so-vits-svc/logs/48k/\" + cloud_model_name\n",
        "config_path = \"/content/so-vits-svc/configs/config.json\"\n",
        "svc_model = Svc(model_path, config_path)\n",
        "infer_tool.mkdir([\"raw\", \"results\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxm7D--GTxgI",
        "outputId": "5c61b20b-1446-414e-ace0-616439adac88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'0': {'slice': False, 'split_time': '0,163170'}, '1': {'slice': True, 'split_time': '163170,163170'}, '2': {'slice': False, 'split_time': '163170,388080'}, '3': {'slice': True, 'split_time': '388080,388080'}, '4': {'slice': False, 'split_time': '388080,652680'}, '5': {'slice': True, 'split_time': '652680,652680'}, '6': {'slice': False, 'split_time': '652680,960498'}, '7': {'slice': True, 'split_time': '960498,960498'}, '8': {'slice': False, 'split_time': '960498,1181880'}, '9': {'slice': True, 'split_time': '1181880,1181880'}, '10': {'slice': False, 'split_time': '1181880,1408554'}, '11': {'slice': True, 'split_time': '1408554,1408554'}, '12': {'slice': False, 'split_time': '1408554,1704024'}, '13': {'slice': True, 'split_time': '1704024,1704024'}, '14': {'slice': False, 'split_time': '1704024,1924524'}, '15': {'slice': True, 'split_time': '1924524,1924524'}, '16': {'slice': False, 'split_time': '1924524,2148552'}, '17': {'slice': True, 'split_time': '2148552,2148552'}, '18': {'slice': False, 'split_time': '2148552,3206952'}, '19': {'slice': True, 'split_time': '3206952,3206952'}, '20': {'slice': False, 'split_time': '3206952,3722922'}, '21': {'slice': True, 'split_time': '3722922,3722922'}, '22': {'slice': False, 'split_time': '3722922,4252122'}, '23': {'slice': True, 'split_time': '4252122,4252122'}, '24': {'slice': False, 'split_time': '4252122,4569642'}, '25': {'slice': True, 'split_time': '4569642,4569642'}, '26': {'slice': False, 'split_time': '4569642,4979772'}, '27': {'slice': True, 'split_time': '4979772,4979772'}, '28': {'slice': False, 'split_time': '4979772,5178222'}, '29': {'slice': True, 'split_time': '5178222,5178222'}, '30': {'slice': False, 'split_time': '5178222,5547780'}, '31': {'slice': True, 'split_time': '5547780,5814191'}}\n",
            "#=====segment start, 3.7s======\n",
            "hubert use time:1.379185438156128\n",
            "vits use time:0.5454626083374023\n",
            "#=====segment start, 5.1s======\n",
            "hubert use time:0.008101940155029297\n",
            "vits use time:0.11954474449157715\n",
            "#=====segment start, 6.0s======\n",
            "hubert use time:0.008344411849975586\n",
            "vits use time:0.1354835033416748\n",
            "#=====segment start, 6.98s======\n",
            "hubert use time:0.008103370666503906\n",
            "vits use time:0.14955592155456543\n",
            "#=====segment start, 5.02s======\n",
            "hubert use time:0.007824897766113281\n",
            "vits use time:0.11627745628356934\n",
            "#=====segment start, 5.14s======\n",
            "hubert use time:0.009253263473510742\n",
            "vits use time:0.11339592933654785\n",
            "#=====segment start, 6.7s======\n",
            "hubert use time:0.008018016815185547\n",
            "vits use time:0.1454765796661377\n",
            "#=====segment start, 5.0s======\n",
            "hubert use time:0.007483243942260742\n",
            "vits use time:0.1138768196105957\n",
            "#=====segment start, 5.08s======\n",
            "hubert use time:0.00727081298828125\n",
            "vits use time:0.11500287055969238\n",
            "#=====segment start, 24.0s======\n",
            "hubert use time:0.012446165084838867\n",
            "vits use time:0.6808822154998779\n",
            "#=====segment start, 11.7s======\n",
            "hubert use time:0.00766301155090332\n",
            "vits use time:0.26468372344970703\n",
            "#=====segment start, 12.0s======\n",
            "hubert use time:0.00801396369934082\n",
            "vits use time:0.271465539932251\n",
            "#=====segment start, 7.2s======\n",
            "hubert use time:0.009601593017578125\n",
            "vits use time:0.1552426815032959\n",
            "#=====segment start, 9.3s======\n",
            "hubert use time:0.00762176513671875\n",
            "vits use time:0.19338560104370117\n",
            "#=====segment start, 4.5s======\n",
            "hubert use time:0.00728154182434082\n",
            "vits use time:0.10541677474975586\n",
            "#=====segment start, 8.38s======\n",
            "hubert use time:0.007960081100463867\n",
            "vits use time:0.179443359375\n",
            "#=====segment start, 6.041s======\n",
            "jump empty segment\n",
            "{'0': {'slice': False, 'split_time': '0,117747'}, '1': {'slice': True, 'split_time': '117747,117747'}, '2': {'slice': False, 'split_time': '117747,220500'}, '3': {'slice': True, 'split_time': '220500,225440'}}\n",
            "#=====segment start, 5.34s======\n",
            "hubert use time:0.007203340530395508\n",
            "vits use time:0.1161489486694336\n",
            "#=====segment start, 4.66s======\n",
            "hubert use time:0.007022857666015625\n",
            "vits use time:0.10785818099975586\n",
            "#=====segment start, 0.224s======\n",
            "jump empty segment\n"
          ]
        }
      ],
      "source": [
        "#@title 在线推理，生成的音频文件在results文件夹内\n",
        "\n",
        "#@markdown 需先将原音频放在raw文件夹下，支持多个wav文件。如有多个，文件名以逗号分隔\n",
        "clean_names_input=\"WHITE_ALBUM_1998_vocals,02770\" #@param {type:\"string\"}\n",
        "clean_names = clean_names_input.split(',') \n",
        "\n",
        "#@markdown 音高调整，支持正负（半音）。如有多个，以逗号分隔\n",
        "trans_input = \"-3,0\" #@param {type:\"string\"}\n",
        "trans = trans_input.split(',')\n",
        "for i in range(len(trans)):\n",
        "  trans[i] = int(trans[i])\n",
        "\n",
        "#@markdown 每次同时合成多语者音色，如有多个，以逗号分隔\n",
        "spk_list_input = \"Altoria\" #@param {type:\"string\"}\n",
        "spk_list = spk_list_input.split(',')\n",
        "\n",
        "#@markdown 默认-40，嘈杂的音频可以-30，干声保留呼吸可以-50\n",
        "slice_db = -40 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown 音频输出格式\n",
        "wav_format = 'flac' #@param {type:\"string\"}\n",
        "\n",
        "infer_tool.fill_a_to_b(trans, clean_names)\n",
        "for clean_name, tran in zip(clean_names, trans):\n",
        "    raw_audio_path = f\"raw/{clean_name}\"\n",
        "    if \".\" not in raw_audio_path:\n",
        "        raw_audio_path += \".wav\"\n",
        "    infer_tool.format_wav(raw_audio_path)\n",
        "    wav_path = Path(raw_audio_path).with_suffix('.wav')\n",
        "    audio, sr = librosa.load(wav_path, mono=True, sr=None)\n",
        "    wav_hash = infer_tool.get_md5(audio)\n",
        "    if wav_hash in chunks_dict.keys():\n",
        "        print(\"load chunks from temp\")\n",
        "        chunks = chunks_dict[wav_hash][\"chunks\"]\n",
        "    else:\n",
        "        chunks = slicer.cut(wav_path, db_thresh=slice_db)\n",
        "    print(chunks)\n",
        "    chunks_dict[wav_hash] = {\"chunks\": chunks, \"time\": int(time.time())}\n",
        "    infer_tool.write_temp(\"inference/chunks_temp.json\", chunks_dict)\n",
        "    audio_data, audio_sr = slicer.chunks2audio(wav_path, chunks)\n",
        "\n",
        "    for spk in spk_list:\n",
        "        audio = []\n",
        "        for (slice_tag, data) in audio_data:\n",
        "            print(f'#=====segment start, {round(len(data) / audio_sr, 3)}s======')\n",
        "            length = int(np.ceil(len(data) / audio_sr * svc_model.target_sample))\n",
        "            raw_path = io.BytesIO()\n",
        "            soundfile.write(raw_path, data, audio_sr, format=\"wav\")\n",
        "            raw_path.seek(0)\n",
        "            if slice_tag:\n",
        "                print('jump empty segment')\n",
        "                _audio = np.zeros(length)\n",
        "            else:\n",
        "                out_audio, out_sr = svc_model.infer(spk, tran, raw_path)\n",
        "                _audio = out_audio.cpu().numpy()\n",
        "            audio.extend(list(_audio))\n",
        "\n",
        "        res_path = f'./results/{clean_name}_{tran}key_{spk}.{wav_format}'\n",
        "        soundfile.write(res_path, audio, svc_model.target_sample, format=wav_format)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}